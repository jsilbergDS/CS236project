{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "EndOfRoad-final.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bebf95b48aa84cb089397754baf76c7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b77322df54ea4af1acf08008b752c937",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f38dfe32adc145a08667c7eb41120cec",
              "IPY_MODEL_d60290afe60244759014c4eac47789d7",
              "IPY_MODEL_cd04708ee45d48d583570abfa12f8ea9"
            ]
          }
        },
        "b77322df54ea4af1acf08008b752c937": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f38dfe32adc145a08667c7eb41120cec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9ee743dd6f7447eba831c9176588f8b0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7e165ffbcd7f474a9eac684fc24d6d11"
          }
        },
        "d60290afe60244759014c4eac47789d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7de5eaf4141a41a084bab181b847e18a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 553433881,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 553433881,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_43a385a697574ba794ee830bc00ba5c8"
          }
        },
        "cd04708ee45d48d583570abfa12f8ea9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5f742c4b4d394a599f12a0e91422b1f1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 528M/528M [00:03&lt;00:00, 161MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d02336b54b5349e19644beba94c7678b"
          }
        },
        "9ee743dd6f7447eba831c9176588f8b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7e165ffbcd7f474a9eac684fc24d6d11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7de5eaf4141a41a084bab181b847e18a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "43a385a697574ba794ee830bc00ba5c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5f742c4b4d394a599f12a0e91422b1f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d02336b54b5349e19644beba94c7678b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Adapted from: https://github.com/JiahuiYu/generative_inpainting\n",
        "\n"
      ],
      "metadata": {
        "id": "ArQYrHCME-Vb"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpMExehptZ79",
        "outputId": "fbb76c57-8b95-47aa-8272-c4fc47c6ea51"
      },
      "source": [
        "!pip install git+https://github.com/JiahuiYu/neuralgym"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/JiahuiYu/neuralgym\n",
            "  Cloning https://github.com/JiahuiYu/neuralgym to /tmp/pip-req-build-7o5_gr9d\n",
            "  Running command git clone -q https://github.com/JiahuiYu/neuralgym /tmp/pip-req-build-7o5_gr9d\n",
            "Building wheels for collected packages: neuralgym\n",
            "  Building wheel for neuralgym (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for neuralgym: filename=neuralgym-0.0.1-py3-none-any.whl size=40441 sha256=8f7a986ebabf4b1f8c60ea3bd0c784e43df4547484f95b517cfbbdeda4440880\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-52b7k2eg/wheels/bf/3a/34/026a730c199a8c4cb5da3c052c71801eaf6618c4771d7faab2\n",
            "Successfully built neuralgym\n",
            "Installing collected packages: neuralgym\n",
            "Successfully installed neuralgym-0.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWzYp9J0exPo",
        "outputId": "78e8aedb-8fdc-4c2e-812b-b1a9147d230c"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow 1.x selected.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "goayV4qGt8ub"
      },
      "source": [
        "import os\n",
        "training_file_names = []\n",
        "validation_file_names = []\n",
        "overall_dir = '/content/drive/MyDrive/BayArea500NoHighways/train'\n",
        "file_list = [f for f in os.listdir(overall_dir) if not f.startswith('.')] \n",
        "for file in file_list:\n",
        "  training_file_names.append(overall_dir+file)\n",
        "overall_dir = '/content/drive/MyDrive/BayArea500NoHighways/train'\n",
        "file_list = [f for f in os.listdir(overall_dir) if not f.startswith('.')] \n",
        "for file in file_list:\n",
        "  validation_file_names.append(overall_dir+file)\n",
        "\n",
        "\n",
        "with open(\"train_shuffled.flist\", \"w\") as train_out:\n",
        "  train_out.write(\"\\n\".join(training_file_names))\n",
        "\n",
        "with open(\"validation.flist\", \"w\") as val_out:\n",
        "  val_out.write(\"\\n\".join(validation_file_names))\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I modify inpaint.yml to load the places2 model as a starting point\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "model_restore: '/content/drive/MyDrive/generative_inpainting/logs/places2' \n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "NhYP-0rFC_z1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/generative_inpainting/train.py"
      ],
      "metadata": {
        "id": "JSMFzkNFBgxW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the pix2pix masks I replaced the following code in inpaint_ops:\n",
        "\n",
        "Replace: \n",
        "\n",
        "\n",
        "\n",
        "```\n",
        " def generate_mask(H, W):\n",
        "        average_radius = math.sqrt(H*H+W*W) / 8\n",
        "        mask = Image.new('L', (W, H), 0)\n",
        "\n",
        "        for _ in range(np.random.randint(1, 4)):\n",
        "            num_vertex = np.random.randint(min_num_vertex, max_num_vertex)\n",
        "            angle_min = mean_angle - np.random.uniform(0, angle_range)\n",
        "            angle_max = mean_angle + np.random.uniform(0, angle_range)\n",
        "            angles = []\n",
        "            vertex = []\n",
        "            for i in range(num_vertex):\n",
        "                if i % 2 == 0:\n",
        "                    angles.append(2*math.pi - np.random.uniform(angle_min, angle_max))\n",
        "                else:\n",
        "                    angles.append(np.random.uniform(angle_min, angle_max))\n",
        "\n",
        "            h, w = mask.size\n",
        "            vertex.append((int(np.random.randint(0, w)), int(np.random.randint(0, h))))\n",
        "            for i in range(num_vertex):\n",
        "                r = np.clip(\n",
        "                    np.random.normal(loc=average_radius, scale=average_radius//2),\n",
        "                    0, 2*average_radius)\n",
        "                new_x = np.clip(vertex[-1][0] + r * math.cos(angles[i]), 0, w)\n",
        "                new_y = np.clip(vertex[-1][1] + r * math.sin(angles[i]), 0, h)\n",
        "                vertex.append((int(new_x), int(new_y)))\n",
        "\n",
        "            draw = ImageDraw.Draw(mask)\n",
        "            width = int(np.random.uniform(min_width, max_width))\n",
        "            draw.line(vertex, fill=1, width=width)\n",
        "            for v in vertex:\n",
        "                draw.ellipse((v[0] - width//2,\n",
        "                              v[1] - width//2,\n",
        "                              v[0] + width//2,\n",
        "                              v[1] + width//2),\n",
        "                             fill=1)\n",
        "\n",
        "        if np.random.normal() > 0:\n",
        "            mask.transpose(Image.FLIP_LEFT_RIGHT)\n",
        "        if np.random.normal() > 0:\n",
        "            mask.transpose(Image.FLIP_TOP_BOTTOM)\n",
        "        mask = np.asarray(mask, np.float32)\n",
        "        mask = np.reshape(mask, (1, H, W, 1))\n",
        "        return mask\n",
        "```\n",
        "\n",
        "With: \n",
        "\n",
        "```\n",
        "    def generate_mask(H, W):\n",
        "        new_rand = np.random.randint(1,250)\n",
        "        sec_rand = np.random.randint(0,7)\n",
        "        mask = Image.open(\"/content/drive/MyDrive/fixed_masks/output_\"+str(new_rand)+\"_fake_B_\"+str(sec_rand)+\".png\")\n",
        "        print(new_rand,\" \",sec_rand)\n",
        "        if np.random.normal() > 0:\n",
        "            mask.transpose(Image.FLIP_LEFT_RIGHT)\n",
        "        if np.random.normal() > 0:\n",
        "            mask.transpose(Image.FLIP_TOP_BOTTOM)\n",
        "        mask = np.asarray(mask, np.float32)\n",
        "        mask = mask[:,:,0]\n",
        "        mask = np.reshape(mask, (1, H, W, 1))\n",
        "        return mask\n",
        "\n",
        "```\n",
        "```"
      ],
      "metadata": {
        "id": "nKVCwJu0BifN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Image generation ###"
      ],
      "metadata": {
        "id": "f6Z1rdI9DYqW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I modify below to generate all test set outputs. Bay_only is the fine-tuned model. "
      ],
      "metadata": {
        "id": "AoZ4NVoWE1Df"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jj_FokSWyQt9",
        "outputId": "14834e19-f19d-408a-d71d-9ed28b4b7b51"
      },
      "source": [
        "%cd /content/drive/MyDrive/generative_inpainting\n",
        "!python /content/drive/MyDrive/generative_inpainting/test.py --image /content/drive/MyDrive/NOLATest/test/output_5.png --mask /content/drive/MyDrive/test_masks/output_5_fake_B_0.png --output /content/drive/MyDrive/NOLATest/test/output_5_gen_final.png --checkpoint_dir /content/drive/MyDrive/generative_inpainting/logs/bay_only\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/generative_inpainting\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/neuralgym/ops/layers.py:142: The name tf.image.resize_bilinear is deprecated. Please use tf.compat.v1.image.resize_bilinear instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/neuralgym/callbacks/npz_model_loader.py:31: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/neuralgym/ops/gan_ops.py:138: The name tf.layers.Conv2D is deprecated. Please use tf.compat.v1.layers.Conv2D instead.\n",
            "\n",
            "---------------------------------- APP CONFIG ----------------------------------\n",
            "num_gpus_per_job: 1\n",
            "num_cpus_per_job: 4\n",
            "num_hosts_per_job: 1\n",
            "memory_per_job: 32\n",
            "gpu_type: nvidia-tesla-p100\n",
            "name: places2_gated_conv_v100\n",
            "model_restore: /content/drive/MyDrive/generative_inpainting/logs/places2\n",
            "dataset: celebahq\n",
            "random_crop: False\n",
            "val: False\n",
            "log_dir: logs/gan_mask\n",
            "gan: sngan\n",
            "gan_loss_alpha: 1\n",
            "gan_with_mask: True\n",
            "discounted_mask: True\n",
            "random_seed: False\n",
            "padding: SAME\n",
            "train_spe: 4000\n",
            "max_iters: 100000000\n",
            "viz_max_out: 10\n",
            "val_psteps: 2000\n",
            "data_flist: \n",
            "  celebahq: ['/content/drive/MyDrive/generative_inpainting/train_shuffled_bay.flist', '/content/drive/MyDrive/generative_inpainting/validation_bay.flist']\n",
            "  celeba: ['data/celeba/train_shuffled.flist', 'data/celeba/validation_static_view.flist']\n",
            "  places2: ['data/places2/train_shuffled.flist', 'data/places2/validation_static_view.flist']\n",
            "  imagenet: ['data/imagenet/train_shuffled.flist', 'data/imagenet/validation_static_view.flist']\n",
            "static_view_size: 30\n",
            "img_shapes: [256, 256, 3]\n",
            "height: 128\n",
            "width: 128\n",
            "max_delta_height: 32\n",
            "max_delta_width: 32\n",
            "batch_size: 16\n",
            "vertical_margin: 0\n",
            "horizontal_margin: 0\n",
            "ae_loss: True\n",
            "l1_loss: True\n",
            "l1_loss_alpha: 1.0\n",
            "guided: False\n",
            "edge_threshold: 0.6\n",
            "--------------------------------------------------------------------------------\n",
            "Shape of image: (256, 256, 3)\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/generative_inpainting/test.py:44: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/generative_inpainting/test.py:46: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2021-12-08 01:46:51.969319: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n",
            "2021-12-08 01:46:51.969506: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55b245832f40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2021-12-08 01:46:51.969537: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2021-12-08 01:46:51.971194: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2021-12-08 01:46:52.217840: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-12-08 01:46:52.218737: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55b2458332c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2021-12-08 01:46:52.218770: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
            "2021-12-08 01:46:52.218957: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-12-08 01:46:52.219527: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-12-08 01:46:52.219828: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-12-08 01:46:52.221193: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-12-08 01:46:52.221983: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-12-08 01:46:52.222302: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-12-08 01:46:52.223662: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-12-08 01:46:52.224351: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-12-08 01:46:52.227153: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-12-08 01:46:52.227264: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-12-08 01:46:52.227840: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-12-08 01:46:52.228361: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2021-12-08 01:46:52.228422: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-12-08 01:46:52.229582: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-12-08 01:46:52.229608: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2021-12-08 01:46:52.229619: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2021-12-08 01:46:52.229736: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-12-08 01:46:52.230316: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-12-08 01:46:52.230848: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15224 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/generative_inpainting/inpaint_model.py:45: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/generative_inpainting/inpaint_ops.py:48: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.keras.layers.Conv2D` instead.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/layers/convolutional.py:424: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/generative_inpainting/inpaint_ops.py:222: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/generative_inpainting/inpaint_ops.py:254: calling extract_image_patches (from tensorflow.python.ops.array_ops) with ksizes is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "ksizes is deprecated, use sizes instead\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/generative_inpainting/inpaint_ops.py:472: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "WARNING:tensorflow:From /content/drive/MyDrive/generative_inpainting/test.py:53: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/generative_inpainting/test.py:53: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/generative_inpainting/test.py:59: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Model loaded.\n",
            "2021-12-08 01:47:06.904578: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-12-08 01:47:07.606092: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Metrics ###"
      ],
      "metadata": {
        "id": "jm2VS8OjDc5j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following section prepares the files to call batch_test.py on my 54 validation image / generated image **pairs**"
      ],
      "metadata": {
        "id": "fL28a953Dg3w"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8bRBofwazNg",
        "outputId": "3b3f0422-76e1-42e3-d644-ae2cf4be4ea5"
      },
      "source": [
        "import os\n",
        "LPIPS_file_names = []\n",
        "overall_dir = '/content/drive/MyDrive/BayArea500NoHighways/val/'\n",
        "file_list = [f for f in os.listdir(overall_dir) if not f.startswith('.')] \n",
        "i = 0\n",
        "for file in file_list:\n",
        "  LPIPS_file_names.append(overall_dir+file+\" \"+\"/content/drive/MyDrive/fixed_masks/output_\"+str(i)+\"_fake_B_0.png\"+\" \"+\"/content/drive/MyDrive/BayArea500NoHighways/metrics/out_\"+file)\n",
        "  i+=1\n",
        "with open(\"/content/test.flist\", \"w\") as val_out:\n",
        "  val_out.write(\"\\n\".join(LPIPS_file_names))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content/drive/MyDrive/BayArea500NoHighways/val/output_451.png /content/drive/MyDrive/fixed_masks/output_0_fake_B_0.png /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_451.png', '/content/drive/MyDrive/BayArea500NoHighways/val/output_453.png /content/drive/MyDrive/fixed_masks/output_1_fake_B_0.png /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_453.png', '/content/drive/MyDrive/BayArea500NoHighways/val/output_452.png /content/drive/MyDrive/fixed_masks/output_2_fake_B_0.png /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_452.png', '/content/drive/MyDrive/BayArea500NoHighways/val/output_454.png /content/drive/MyDrive/fixed_masks/output_3_fake_B_0.png /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_454.png', '/content/drive/MyDrive/BayArea500NoHighways/val/output_456.png /content/drive/MyDrive/fixed_masks/output_4_fake_B_0.png /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_456.png', '/content/drive/MyDrive/BayArea500NoHighways/val/output_455.png /content/drive/MyDrive/fixed_masks/output_5_fake_B_0.png /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_455.png', '/content/drive/MyDrive/BayArea500NoHighways/val/output_457.png /content/drive/MyDrive/fixed_masks/output_6_fake_B_0.png /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_457.png', '/content/drive/MyDrive/BayArea500NoHighways/val/output_459.png /content/drive/MyDrive/fixed_masks/output_7_fake_B_0.png /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_459.png', '/content/drive/MyDrive/BayArea500NoHighways/val/output_458.png /content/drive/MyDrive/fixed_masks/output_8_fake_B_0.png /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_458.png', '/content/drive/MyDrive/BayArea500NoHighways/val/output_460.png /content/drive/MyDrive/fixed_masks/output_9_fake_B_0.png /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_460.png', '/content/drive/MyDrive/BayArea500NoHighways/val/output_462.png /content/drive/MyDrive/fixed_masks/output_10_fake_B_0.png /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_462.png', '/content/drive/MyDrive/BayArea500NoHighways/val/output_461.png /content/drive/MyDrive/fixed_masks/output_11_fake_B_0.png /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_461.png', '/content/drive/MyDrive/BayArea500NoHighways/val/output_463.png /content/drive/MyDrive/fixed_masks/output_12_fake_B_0.png /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_463.png', '/content/drive/MyDrive/BayArea500NoHighways/val/output_464.png /content/drive/MyDrive/fixed_masks/output_13_fake_B_0.png /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_464.png', '/content/drive/MyDrive/BayArea500NoHighways/val/output_465.png /content/drive/MyDrive/fixed_masks/output_14_fake_B_0.png /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_465.png', '/content/drive/MyDrive/BayArea500NoHighways/val/output_466.png /content/drive/MyDrive/fixed_masks/output_15_fake_B_0.png /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_466.png', '/content/drive/MyDrive/BayArea500NoHighways/val/output_467.png /content/drive/MyDrive/fixed_masks/output_16_fake_B_0.png /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_467.png', '/content/drive/MyDrive/BayArea500NoHighways/val/output_468.png /content/drive/MyDrive/fixed_masks/output_17_fake_B_0.png /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_468.png', '/content/drive/MyDrive/BayArea500NoHighways/val/output_469.png /content/drive/MyDrive/fixed_masks/output_18_fake_B_0.png /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_469.png', '/content/drive/MyDrive/BayArea500NoHighways/val/output_470.png /content/drive/MyDrive/fixed_masks/output_19_fake_B_0.png /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_470.png', '/content/drive/MyDrive/BayArea500NoHighways/val/output_471.png /content/drive/MyDrive/fixed_masks/output_20_fake_B_0.png /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_471.png', '/content/drive/MyDrive/BayArea500NoHighways/val/output_472.png /content/drive/MyDrive/fixed_masks/output_21_fake_B_0.png /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_472.png', '/content/drive/MyDrive/BayArea500NoHighways/val/output_473.png /content/drive/MyDrive/fixed_masks/output_22_fake_B_0.png /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_473.png', '/content/drive/MyDrive/BayArea500NoHighways/val/output_474.png /content/drive/MyDrive/fixed_masks/output_23_fake_B_0.png /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_474.png', '/content/drive/MyDrive/BayArea500NoHighways/val/output_475.png /content/drive/MyDrive/fixed_masks/output_24_fake_B_0.png /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_475.png', '/content/drive/MyDrive/BayArea500NoHighways/val/output_476.png /content/drive/MyDrive/fixed_masks/output_25_fake_B_0.png /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_476.png', '/content/drive/MyDrive/BayArea500NoHighways/val/output_477.png /content/drive/MyDrive/fixed_masks/output_26_fake_B_0.png /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_477.png', '/content/drive/MyDrive/BayArea500NoHighways/val/output_479.png /content/drive/MyDrive/fixed_masks/output_27_fake_B_0.png /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_479.png', '/content/drive/MyDrive/BayArea500NoHighways/val/output_478.png /content/drive/MyDrive/fixed_masks/output_28_fake_B_0.png /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_478.png', '/content/drive/MyDrive/BayArea500NoHighways/val/output_480.png /content/drive/MyDrive/fixed_masks/output_29_fake_B_0.png /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_480.png', '/content/drive/MyDrive/BayArea500NoHighways/val/output_481.png /content/drive/MyDrive/fixed_masks/output_30_fake_B_0.png /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_481.png', '/content/drive/MyDrive/BayArea500NoHighways/val/output_482.png /content/drive/MyDrive/fixed_masks/output_31_fake_B_0.png /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_482.png', '/content/drive/MyDrive/BayArea500NoHighways/val/output_483.png /content/drive/MyDrive/fixed_masks/output_32_fake_B_0.png /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_483.png', '/content/drive/MyDrive/BayArea500NoHighways/val/output_484.png /content/drive/MyDrive/fixed_masks/output_33_fake_B_0.png /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_484.png', '/content/drive/MyDrive/BayArea500NoHighways/val/output_485.png /content/drive/MyDrive/fixed_masks/output_34_fake_B_0.png /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_485.png', '/content/drive/MyDrive/BayArea500NoHighways/val/output_486.png /content/drive/MyDrive/fixed_masks/output_35_fake_B_0.png /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_486.png', '/content/drive/MyDrive/BayArea500NoHighways/val/output_487.png /content/drive/MyDrive/fixed_masks/output_36_fake_B_0.png /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_487.png', '/content/drive/MyDrive/BayArea500NoHighways/val/output_488.png /content/drive/MyDrive/fixed_masks/output_37_fake_B_0.png /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_488.png', '/content/drive/MyDrive/BayArea500NoHighways/val/output_489.png /content/drive/MyDrive/fixed_masks/output_38_fake_B_0.png /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_489.png', '/content/drive/MyDrive/BayArea500NoHighways/val/output_490.png /content/drive/MyDrive/fixed_masks/output_39_fake_B_0.png /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_490.png', '/content/drive/MyDrive/BayArea500NoHighways/val/output_491.png /content/drive/MyDrive/fixed_masks/output_40_fake_B_0.png /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_491.png', '/content/drive/MyDrive/BayArea500NoHighways/val/output_492.png /content/drive/MyDrive/fixed_masks/output_41_fake_B_0.png /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_492.png', '/content/drive/MyDrive/BayArea500NoHighways/val/output_493.png /content/drive/MyDrive/fixed_masks/output_42_fake_B_0.png /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_493.png', '/content/drive/MyDrive/BayArea500NoHighways/val/output_494.png /content/drive/MyDrive/fixed_masks/output_43_fake_B_0.png /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_494.png', '/content/drive/MyDrive/BayArea500NoHighways/val/output_495.png /content/drive/MyDrive/fixed_masks/output_44_fake_B_0.png /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_495.png', '/content/drive/MyDrive/BayArea500NoHighways/val/output_496.png /content/drive/MyDrive/fixed_masks/output_45_fake_B_0.png /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_496.png', '/content/drive/MyDrive/BayArea500NoHighways/val/output_497.png /content/drive/MyDrive/fixed_masks/output_46_fake_B_0.png /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_497.png', '/content/drive/MyDrive/BayArea500NoHighways/val/output_498.png /content/drive/MyDrive/fixed_masks/output_47_fake_B_0.png /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_498.png', '/content/drive/MyDrive/BayArea500NoHighways/val/output_499.png /content/drive/MyDrive/fixed_masks/output_48_fake_B_0.png /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_499.png', '/content/drive/MyDrive/BayArea500NoHighways/val/output_500.png /content/drive/MyDrive/fixed_masks/output_49_fake_B_0.png /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_500.png', '/content/drive/MyDrive/BayArea500NoHighways/val/output_501.png /content/drive/MyDrive/fixed_masks/output_50_fake_B_0.png /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_501.png', '/content/drive/MyDrive/BayArea500NoHighways/val/output_503.png /content/drive/MyDrive/fixed_masks/output_51_fake_B_0.png /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_503.png', '/content/drive/MyDrive/BayArea500NoHighways/val/output_502.png /content/drive/MyDrive/fixed_masks/output_52_fake_B_0.png /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_502.png', '/content/drive/MyDrive/BayArea500NoHighways/val/output_504.png /content/drive/MyDrive/fixed_masks/output_53_fake_B_0.png /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_504.png']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I use batch_test to generate the 54 real/fake pairs by modifying the checkpoint below. gan_mask is the model trained with the pix2pix masks\n",
        "\n",
        "I draw on: https://torchmetrics.readthedocs.io/en/latest/references/modules.html#id8"
      ],
      "metadata": {
        "id": "NtzgMktMDtBc"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Swhh4H7YbBLv",
        "outputId": "18c476a6-db8d-4cd3-eb59-4da7738c6e93"
      },
      "source": [
        "%cd /content/drive/MyDrive/generative_inpainting\n",
        "!python /content/drive/MyDrive/generative_inpainting/batch_test.py --flist /content/test.flist --image_height 256 --image_width 256 --checkpoint_dir /content/drive/MyDrive/generative_inpainting/logs/gan_mask"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/generative_inpainting\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/neuralgym/ops/layers.py:142: The name tf.image.resize_bilinear is deprecated. Please use tf.compat.v1.image.resize_bilinear instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/neuralgym/callbacks/npz_model_loader.py:31: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/neuralgym/ops/gan_ops.py:138: The name tf.layers.Conv2D is deprecated. Please use tf.compat.v1.layers.Conv2D instead.\n",
            "\n",
            "---------------------------------- APP CONFIG ----------------------------------\n",
            "num_gpus_per_job: 1\n",
            "num_cpus_per_job: 4\n",
            "num_hosts_per_job: 1\n",
            "memory_per_job: 32\n",
            "gpu_type: nvidia-tesla-p100\n",
            "name: places2_gated_conv_v100\n",
            "model_restore: /content/drive/MyDrive/generative_inpainting/logs/places2\n",
            "dataset: celebahq\n",
            "random_crop: False\n",
            "val: False\n",
            "log_dir: logs/gan_mask\n",
            "gan: sngan\n",
            "gan_loss_alpha: 1\n",
            "gan_with_mask: True\n",
            "discounted_mask: True\n",
            "random_seed: False\n",
            "padding: SAME\n",
            "train_spe: 4000\n",
            "max_iters: 100000000\n",
            "viz_max_out: 10\n",
            "val_psteps: 2000\n",
            "data_flist: \n",
            "  celebahq: ['/content/drive/MyDrive/generative_inpainting/train_shuffled_bay.flist', '/content/drive/MyDrive/generative_inpainting/validation_bay.flist']\n",
            "  celeba: ['data/celeba/train_shuffled.flist', 'data/celeba/validation_static_view.flist']\n",
            "  places2: ['data/places2/train_shuffled.flist', 'data/places2/validation_static_view.flist']\n",
            "  imagenet: ['data/imagenet/train_shuffled.flist', 'data/imagenet/validation_static_view.flist']\n",
            "static_view_size: 30\n",
            "img_shapes: [256, 256, 3]\n",
            "height: 128\n",
            "width: 128\n",
            "max_delta_height: 32\n",
            "max_delta_width: 32\n",
            "batch_size: 16\n",
            "vertical_margin: 0\n",
            "horizontal_margin: 0\n",
            "ae_loss: True\n",
            "l1_loss: True\n",
            "l1_loss_alpha: 1.0\n",
            "guided: False\n",
            "edge_threshold: 0.6\n",
            "--------------------------------------------------------------------------------\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/generative_inpainting/batch_test.py:36: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/generative_inpainting/batch_test.py:38: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2021-12-08 00:11:23.664506: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n",
            "2021-12-08 00:11:23.664700: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55fa6092ef40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2021-12-08 00:11:23.664729: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2021-12-08 00:11:23.666355: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2021-12-08 00:11:23.902689: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-12-08 00:11:23.903583: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55fa6092f2c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2021-12-08 00:11:23.903617: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
            "2021-12-08 00:11:23.903809: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-12-08 00:11:23.904411: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-12-08 00:11:23.904730: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-12-08 00:11:23.906159: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-12-08 00:11:23.906996: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-12-08 00:11:23.907310: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-12-08 00:11:23.908810: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-12-08 00:11:23.909528: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-12-08 00:11:23.912461: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-12-08 00:11:23.912586: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-12-08 00:11:23.913223: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-12-08 00:11:23.913779: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2021-12-08 00:11:23.913837: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-12-08 00:11:23.915052: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-12-08 00:11:23.915081: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2021-12-08 00:11:23.915092: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2021-12-08 00:11:23.915214: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-12-08 00:11:23.915820: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-12-08 00:11:23.916402: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15224 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/generative_inpainting/batch_test.py:41: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/generative_inpainting/inpaint_model.py:45: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/generative_inpainting/inpaint_ops.py:48: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.keras.layers.Conv2D` instead.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/layers/convolutional.py:424: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/generative_inpainting/inpaint_ops.py:222: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/generative_inpainting/inpaint_ops.py:254: calling extract_image_patches (from tensorflow.python.ops.array_ops) with ksizes is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "ksizes is deprecated, use sizes instead\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/generative_inpainting/inpaint_ops.py:472: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "WARNING:tensorflow:From /content/drive/MyDrive/generative_inpainting/batch_test.py:47: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/generative_inpainting/batch_test.py:47: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/generative_inpainting/batch_test.py:54: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Model loaded.\n",
            "Shape of image: (256, 256, 3)\n",
            "2021-12-08 00:11:45.483915: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-12-08 00:11:47.495914: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "Processed: /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_451.png\n",
            "Shape of image: (256, 256, 3)\n",
            "Processed: /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_453.png\n",
            "Shape of image: (256, 256, 3)\n",
            "Processed: /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_452.png\n",
            "Shape of image: (256, 256, 3)\n",
            "Processed: /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_454.png\n",
            "Shape of image: (256, 256, 3)\n",
            "Processed: /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_456.png\n",
            "Shape of image: (256, 256, 3)\n",
            "Processed: /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_455.png\n",
            "Shape of image: (256, 256, 3)\n",
            "Processed: /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_457.png\n",
            "Shape of image: (256, 256, 3)\n",
            "Processed: /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_459.png\n",
            "Shape of image: (256, 256, 3)\n",
            "Processed: /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_458.png\n",
            "Shape of image: (256, 256, 3)\n",
            "Processed: /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_460.png\n",
            "Shape of image: (256, 256, 3)\n",
            "Processed: /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_462.png\n",
            "Shape of image: (256, 256, 3)\n",
            "Processed: /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_461.png\n",
            "Shape of image: (256, 256, 3)\n",
            "Processed: /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_463.png\n",
            "Shape of image: (256, 256, 3)\n",
            "Processed: /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_464.png\n",
            "Shape of image: (256, 256, 3)\n",
            "Processed: /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_465.png\n",
            "Shape of image: (256, 256, 3)\n",
            "Processed: /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_466.png\n",
            "Shape of image: (256, 256, 3)\n",
            "Processed: /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_467.png\n",
            "Shape of image: (256, 256, 3)\n",
            "Processed: /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_468.png\n",
            "Shape of image: (256, 256, 3)\n",
            "Processed: /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_469.png\n",
            "Shape of image: (256, 256, 3)\n",
            "Processed: /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_470.png\n",
            "Shape of image: (256, 256, 3)\n",
            "Processed: /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_471.png\n",
            "Shape of image: (256, 256, 3)\n",
            "Processed: /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_472.png\n",
            "Shape of image: (256, 256, 3)\n",
            "Processed: /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_473.png\n",
            "Shape of image: (256, 256, 3)\n",
            "Processed: /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_474.png\n",
            "Shape of image: (256, 256, 3)\n",
            "Processed: /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_475.png\n",
            "Shape of image: (256, 256, 3)\n",
            "Processed: /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_476.png\n",
            "Shape of image: (256, 256, 3)\n",
            "Processed: /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_477.png\n",
            "Shape of image: (256, 256, 3)\n",
            "Processed: /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_479.png\n",
            "Shape of image: (256, 256, 3)\n",
            "Processed: /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_478.png\n",
            "Shape of image: (256, 256, 3)\n",
            "Processed: /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_480.png\n",
            "Shape of image: (256, 256, 3)\n",
            "Processed: /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_481.png\n",
            "Shape of image: (256, 256, 3)\n",
            "Processed: /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_482.png\n",
            "Shape of image: (256, 256, 3)\n",
            "Processed: /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_483.png\n",
            "Shape of image: (256, 256, 3)\n",
            "Processed: /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_484.png\n",
            "Shape of image: (256, 256, 3)\n",
            "Processed: /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_485.png\n",
            "Shape of image: (256, 256, 3)\n",
            "Processed: /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_486.png\n",
            "Shape of image: (256, 256, 3)\n",
            "Processed: /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_487.png\n",
            "Shape of image: (256, 256, 3)\n",
            "Processed: /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_488.png\n",
            "Shape of image: (256, 256, 3)\n",
            "Processed: /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_489.png\n",
            "Shape of image: (256, 256, 3)\n",
            "Processed: /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_490.png\n",
            "Shape of image: (256, 256, 3)\n",
            "Processed: /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_491.png\n",
            "Shape of image: (256, 256, 3)\n",
            "Processed: /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_492.png\n",
            "Shape of image: (256, 256, 3)\n",
            "Processed: /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_493.png\n",
            "Shape of image: (256, 256, 3)\n",
            "Processed: /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_494.png\n",
            "Shape of image: (256, 256, 3)\n",
            "Processed: /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_495.png\n",
            "Shape of image: (256, 256, 3)\n",
            "Processed: /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_496.png\n",
            "Shape of image: (256, 256, 3)\n",
            "Processed: /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_497.png\n",
            "Shape of image: (256, 256, 3)\n",
            "Processed: /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_498.png\n",
            "Shape of image: (256, 256, 3)\n",
            "Processed: /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_499.png\n",
            "Shape of image: (256, 256, 3)\n",
            "Processed: /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_500.png\n",
            "Shape of image: (256, 256, 3)\n",
            "Processed: /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_501.png\n",
            "Shape of image: (256, 256, 3)\n",
            "Processed: /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_503.png\n",
            "Shape of image: (256, 256, 3)\n",
            "Processed: /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_502.png\n",
            "Shape of image: (256, 256, 3)\n",
            "Processed: /content/drive/MyDrive/BayArea500NoHighways/bad/out_output_504.png\n",
            "Time total: 47.006192445755005\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I vectorize the 54 images"
      ],
      "metadata": {
        "id": "m0B2dAFRD-j6"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0MBtjqzbhAo",
        "outputId": "aecbbf44-508b-471a-cd88-c2d16aaae635"
      },
      "source": [
        "import torch\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "convert = transforms.ToTensor()\n",
        "image_fake = Image.open(\"/content/drive/MyDrive/BayArea500NoHighways/bad/out_output_452.png\")\n",
        "t_fake = convert(image_fake)\n",
        "t_fake = t_fake[0:3,:,:]\n",
        "t_fake = torch.unsqueeze(t_fake,0)\n",
        "image_real = Image.open(\"/content/drive/MyDrive/BayArea500NoHighways/val/output_452.png\")\n",
        "t_real = convert(image_real)\n",
        "t_real = t_real[0:3,:,:]\n",
        "t_real = torch.unsqueeze(t_real,0)\n",
        "for i in range(451,504):\n",
        "  image = Image.open(\"/content/drive/MyDrive/BayArea500NoHighways/bad/out_output_\"+str(i)+\".png\")\n",
        "  t1 = convert(image)\n",
        "  t1 = t1[0:3,:,:]\n",
        "  t1 = torch.unsqueeze(t1,0)\n",
        "  t_fake = torch.cat((t_fake,t1),dim=0)\n",
        "  image = Image.open(\"/content/drive/MyDrive/BayArea500NoHighways/val/output_\"+str(i)+\".png\")\n",
        "  t2 = convert(image)\n",
        "  t2 = t2[0:3,:,:]\n",
        "  t2 = torch.unsqueeze(t2,0)\n",
        "  t_real = torch.cat((t_real,t2),dim=0)\n",
        "print(t_real.size())\n",
        "print(t_fake.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([54, 3, 256, 256])\n",
            "torch.Size([54, 3, 256, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433,
          "referenced_widgets": [
            "bebf95b48aa84cb089397754baf76c7a",
            "b77322df54ea4af1acf08008b752c937",
            "f38dfe32adc145a08667c7eb41120cec",
            "d60290afe60244759014c4eac47789d7",
            "cd04708ee45d48d583570abfa12f8ea9",
            "9ee743dd6f7447eba831c9176588f8b0",
            "7e165ffbcd7f474a9eac684fc24d6d11",
            "7de5eaf4141a41a084bab181b847e18a",
            "43a385a697574ba794ee830bc00ba5c8",
            "5f742c4b4d394a599f12a0e91422b1f1",
            "d02336b54b5349e19644beba94c7678b"
          ]
        },
        "id": "5SD_KBxIbl0c",
        "outputId": "5ebebb09-f5d0-4d00-a71c-6f2dcc0fa3bb"
      },
      "source": [
        "#!pip install torchmetrics[image]\n",
        "#!pip install lpips\n",
        "from torchmetrics.image.lpip_similarity import LPIPS\n",
        "lpips = LPIPS(net_type='vgg')\n",
        "lpips(t_real, t_fake)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchmetrics[image]\n",
            "  Downloading torchmetrics-0.6.1-py3-none-any.whl (332 kB)\n",
            "\u001b[K     |████████████████████████████████| 332 kB 7.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torchmetrics[image]) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from torchmetrics[image]) (1.19.5)\n",
            "Requirement already satisfied: torch>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from torchmetrics[image]) (1.10.0+cu111)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from torchmetrics[image]) (0.11.1+cu111)\n",
            "Collecting lpips\n",
            "  Downloading lpips-0.1.4-py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 2.8 MB/s \n",
            "\u001b[?25hCollecting torch-fidelity\n",
            "  Downloading torch_fidelity-0.3.0-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torchmetrics[image]) (1.4.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3.1->torchmetrics[image]) (3.10.0.2)\n",
            "Requirement already satisfied: tqdm>=4.28.1 in /usr/local/lib/python3.7/dist-packages (from lpips->torchmetrics[image]) (4.62.3)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->torchmetrics[image]) (7.1.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->torchmetrics[image]) (3.0.6)\n",
            "Installing collected packages: torchmetrics, torch-fidelity, lpips\n",
            "Successfully installed lpips-0.1.4 torch-fidelity-0.3.0 torchmetrics-0.6.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bebf95b48aa84cb089397754baf76c7a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0.00/528M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.1163], grad_fn=<DivBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkWzyqFHWnGI",
        "outputId": "7bd8a2c8-a695-43ac-db6d-635a3fb158b4"
      },
      "source": [
        "from torchmetrics.image.inception import IS\n",
        "_ = torch.manual_seed(3)\n",
        "inception = IS()\n",
        "t_fake = t_fake *255\n",
        "t_fake = torch.tensor(t_fake,dtype=torch.uint8)\n",
        "inception.update(t_fake)  \n",
        "inception.compute() "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `IS` will save all extracted features in buffer. For large datasets this may lead to large memory footprint.\n",
            "  warnings.warn(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(1.), tensor(6.2829e-08))"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9JE24o99jFDb",
        "outputId": "d7f150fb-cad7-4f18-cd3a-3d230bf91ede"
      },
      "source": [
        "from torchmetrics.image.fid import FID\n",
        "fid = FID(feature=2048)\n",
        "_ = torch.manual_seed(3)\n",
        "t_real = t_real *255\n",
        "t_real = torch.tensor(t_real,dtype=torch.uint8)\n",
        "fid.update(t_real, real=True)  \n",
        "fid.update(t_fake, real=False)  \n",
        "fid.compute()  \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `FID` will save all extracted features in buffer. For large datasets this may lead to large memory footprint.\n",
            "  warnings.warn(*args, **kwargs)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  import sys\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(54.4727)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I create the vectorized tensor to call IS scores on the test set and re-call cell above"
      ],
      "metadata": {
        "id": "ah-FQmFFEmrD"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ncw2vNmiWFbz"
      },
      "source": [
        "convert = transforms.ToTensor()\n",
        "image_fake = Image.open(\"/content/drive/MyDrive/BayAreaTest/test/output_1_gen_gan.png\")\n",
        "t_fake = convert(image_fake)\n",
        "t_fake = t_fake[0:3,:,:]\n",
        "t_fake = torch.unsqueeze(t_fake,0)\n",
        "for i in range(2,6):\n",
        "  image = Image.open(\"/content/drive/MyDrive/BayAreaTest/test/output_\"+str(i)+\"_gen_gan.png\")\n",
        "  t1 = convert(image)\n",
        "  t1 = t1[0:3,:,:]\n",
        "  t1 = torch.unsqueeze(t1,0)\n",
        "  t_fake = torch.cat((t_fake,t1),dim=0)\n",
        "for i in range(1,6):\n",
        "  image = Image.open(\"/content/drive/MyDrive/NOLATest/test/output_\"+str(i)+\"_gen_gan.png\")\n",
        "  t1 = convert(image)\n",
        "  t1 = t1[0:3,:,:]\n",
        "  t1 = torch.unsqueeze(t1,0)\n",
        "  t_fake = torch.cat((t_fake,t1),dim=0)\n",
        "t_fake = t_fake *255\n",
        "t_fake = torch.tensor(t_fake,dtype=torch.uint8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "acazX160Eh8w"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6KMpq8En8Lkj",
        "outputId": "163e9306-e397-49a4-a203-679b7024abcd"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    }
  ]
}