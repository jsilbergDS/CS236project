{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "pix2pix-final",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "environment": {
      "name": "tf2-gpu.2-3.m74",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m74"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jsilbergDS/CS236project/blob/main/pix2pix_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adapted from: https://github.com/phillipi/pix2pix"
      ],
      "metadata": {
        "id": "77WnZ8TaXtd0"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRm-USlsHgEV"
      },
      "source": [
        "!git clone https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pt3igws3eiVp"
      },
      "source": [
        "import os\n",
        "os.chdir('pytorch-CycleGAN-and-pix2pix/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1EySlOXwwoa"
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I pair the original highway images with my hand-drawn masks"
      ],
      "metadata": {
        "id": "dhfo6krnXxSk"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3ZW6ddI5_W9",
        "outputId": "cea45581-84e7-4b12-af93-663e3ee8374e"
      },
      "source": [
        "!python datasets/combine_A_and_B.py --fold_A /content/drive/MyDrive/BayAreaHighway250Raw_pix --fold_B /content/drive/MyDrive/BayAreaHighway250Mask2 --fold_AB /content/drive/MyDrive/BayAreaHighway250AB_pix"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold_A] =  /content/drive/MyDrive/BayAreaHighway250Raw_pix\n",
            "[fold_B] =  /content/drive/MyDrive/BayAreaHighway250Mask2\n",
            "[fold_AB] =  /content/drive/MyDrive/BayAreaHighway250AB_pix\n",
            "[num_imgs] =  1000000\n",
            "[use_AB] =  False\n",
            "[no_multiprocessing] =  False\n",
            "split = train, use 100/100 images\n",
            "split = train, number of images = 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "758bFCAr6rvz"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I install the pre-trained model to improve on"
      ],
      "metadata": {
        "id": "qDB5yZodX9Qz"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GC2DEP4M0OsS"
      },
      "source": [
        "!bash ./scripts/download_pix2pix_model.sh sat2map"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I finetune the model with the data pairs"
      ],
      "metadata": {
        "id": "WLX9ZJgfYDM8"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sp7TCT2x9dB"
      },
      "source": [
        "!python train.py --dataroot /content/drive/MyDrive/BayAreaHighway250AB_pix --name sat2map_pretrained --model pix2pix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UkcaFZiyASl"
      },
      "source": [
        "# Testing\n",
        "\n",
        "-   `python test.py --dataroot ./datasets/facades --direction BtoA --model pix2pix --name facades_pix2pix`\n",
        "\n",
        "Change the `--dataroot`, `--name`, and `--direction` to be consistent with your trained model's configuration and how you want to transform images.\n",
        "\n",
        "> from https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix:\n",
        "> Note that we specified --direction BtoA as Facades dataset's A to B direction is photos to labels.\n",
        "\n",
        "> If you would like to apply a pre-trained model to a collection of input images (rather than image pairs), please use --model test option. See ./scripts/test_single.sh for how to apply a model to Facade label maps (stored in the directory facades/testB).\n",
        "\n",
        "> See a list of currently available models at ./scripts/download_pix2pix_model.sh"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I pair the test set to create the test set masks"
      ],
      "metadata": {
        "id": "KKaWQXSrYK-N"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CI2ulrpTFpWB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc2e655e-0795-4751-8ad0-b39b270556e8"
      },
      "source": [
        "!python datasets/combine_A_and_B.py --fold_A /content/drive/MyDrive/NOLATest --fold_B /content/drive/MyDrive/NOLATest --fold_AB /content/drive/MyDrive/NOLATestAB"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold_A] =  /content/drive/MyDrive/NOLATest\n",
            "[fold_B] =  /content/drive/MyDrive/NOLATest\n",
            "[fold_AB] =  /content/drive/MyDrive/NOLATestAB\n",
            "[num_imgs] =  1000000\n",
            "[use_AB] =  False\n",
            "[no_multiprocessing] =  False\n",
            "split = test, use 5/5 images\n",
            "split = test, number of images = 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I run inference on the test set. I would change this to run inference on 250 unpaired highway images to create the training masks for the \"full model\" configuration. Within utils I edit:     \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "def save_images(webpage, visuals, image_path, aspect_ratio=1.0, width=256, use_wandb=False):\n",
        "    \"\"\"Save images to the disk.\n",
        "\n",
        "    Parameters:\n",
        "        webpage (the HTML class) -- the HTML webpage class that stores these imaegs (see html.py for more details)\n",
        "        visuals (OrderedDict)    -- an ordered dictionary that stores (name, images (either tensor or numpy) ) pairs\n",
        "        image_path (str)         -- the string is used to create image paths\n",
        "        aspect_ratio (float)     -- the aspect ratio of saved images\n",
        "        width (int)              -- the images will be resized to width x width\n",
        "\n",
        "    This function will save images stored in 'visuals' to the HTML file specified by 'webpage'.\n",
        "    \"\"\"\n",
        "    image_dir = webpage.get_image_dir()\n",
        "    short_path = ntpath.basename(image_path[0])\n",
        "    name = os.path.splitext(short_path)[0]\n",
        "\n",
        "    webpage.add_header(name)\n",
        "    ims, txts, links = [], [], []\n",
        "    ims_dict = {}\n",
        "    for label, im_data in visuals.items():\n",
        "        im = util.tensor2im(im_data)\n",
        "        image_name = '%s_%s.png' % (name, label)\n",
        "        save_path = os.path.join(image_dir, image_name)\n",
        "        util.save_image(im, save_path, aspect_ratio=aspect_ratio)\n",
        "        ims.append(image_name)\n",
        "        txts.append(label)\n",
        "        links.append(image_name)\n",
        "        if use_wandb:\n",
        "            ims_dict[label] = wandb.Image(im)\n",
        "    webpage.add_images(ims, txts, links, width=width)\n",
        "    if use_wandb:\n",
        "        wandb.log(ims_dict)\n",
        "```\n",
        "\n",
        "With\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "def save_images(webpage, visuals, image_path, aspect_ratio=1.0, width=256, use_wandb=False):\n",
        "    \"\"\"Save images to the disk.\n",
        "\n",
        "    Parameters:\n",
        "        webpage (the HTML class) -- the HTML webpage class that stores these imaegs (see html.py for more details)\n",
        "        visuals (OrderedDict)    -- an ordered dictionary that stores (name, images (either tensor or numpy) ) pairs\n",
        "        image_path (str)         -- the string is used to create image paths\n",
        "        aspect_ratio (float)     -- the aspect ratio of saved images\n",
        "        width (int)              -- the images will be resized to width x width\n",
        "\n",
        "    This function will save images stored in 'visuals' to the HTML file specified by 'webpage'.\n",
        "    \"\"\"\n",
        "    image_dir = webpage.get_image_dir()\n",
        "    short_path = ntpath.basename(image_path[0])\n",
        "    name = os.path.splitext(short_path)[0]\n",
        "\n",
        "    webpage.add_header(name)\n",
        "    ims, txts, links = [], [], []\n",
        "    ims_dict = {}\n",
        "    for label, im_data in visuals.items():\n",
        "      if label == \"fake_B\"\n",
        "        im = util.tensor2im(im_data)\n",
        "        image_name = '%s_%s.png' % (name, label)\n",
        "        save_path = os.path.join(image_dir, image_name)\n",
        "        util.save_image(im, save_path, aspect_ratio=aspect_ratio)\n",
        "        ims.append(image_name)\n",
        "        txts.append(label)\n",
        "        links.append(image_name)\n",
        "        if use_wandb:\n",
        "            ims_dict[label] = wandb.Image(im)\n",
        "    webpage.add_images(ims, txts, links, width=width)\n",
        "    if use_wandb:\n",
        "        wandb.log(ims_dict)\n",
        "```\n",
        "\n",
        "To create cleaner folders with only the test masks I need\n"
      ],
      "metadata": {
        "id": "g4fPEnxiYRfP"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCsKkEq0yGh0"
      },
      "source": [
        "!python test.py --dataroot /content/drive/MyDrive/NOLATestAB --model pix2pix --name sat2map_pretrained --checkpoints_dir /content/drive/MyDrive/checkpoints"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}